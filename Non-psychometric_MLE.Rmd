---
title: "Non-psychometric MLE"
author: "Olsson et al."
date: "1/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Non-psychometric MLE chromatic background. 



## Load Package for Mixed-Effects Modelling


```{r}
library('readr')
library('boot')
library('lme4')
library('MASS')
library('lmerTest')
library('DHARMa')
```

Read in data.

```{r}
col.dta <- read_delim('colour_discriminate_short_format.txt', delim='\t')
data <- col.dta
data$stimuli <- factor(data$stimuli)
data$target <- with(data, ifelse(background == stimuli, 'same', 'diff'))
data$target <- as.factor(data$target)
data$background <- factor(data$background)
data$ind <- factor(data$ind)
data$batch <- as.factor(data$batch)
data$chick <- paste0(data$ind, data$batch)
```


#	Useful Functions

```{r}
resplot <- function(mod){
#are residuals normally distributed
hist(residuals(mod), prob = T, xlab = formula(mod), main = paste('Residuals for',(formula(mod)[3])))# this actually looks OK to me
lines(density(residuals(mod)), col = 'red')
lines(seq(min(residuals(mod)),max(residuals(mod)), length.out = 10^3), dnorm(seq(min(residuals(mod)),max(residuals(mod)), length.out = 10^3), 0, sd(residuals(mod))), col = 'blue')
legend('topright', legend = c('kernel density', 'fitted normal'), lty = 1, col = c('red', 'blue'))
boxplot(residuals(mod),
		add = T, axes = F, horizontal = T, cex = 0.5, outline = T, border = rgb(0,0.1,0,0.7), at = par('yaxp')[2]*0.1,
		pars = list(boxwex = par('yaxp')[2]*0.3, staplewex = par('yaxp')[2]*0.5, outwex = par('yaxp')[2]*0.05))#
} 
```

##	Fit Logistic Regression

Logistic regression fits a relationship between a binomial variable (yes|no, correct|incorrect, present|absent, 1|0) and any other predictor variable. 
Variance in binomial variable is constrained by the fact that there cannot be > 
100% 1s or 0s in a dataset, so relationships always follow an "S" curve. fit a mixed-effects (both controlled ['fixed'] and unpredictable ['random'] effects) logistic regression predicting 'response' (a correct or incorrect) 
and taking into accound different intercepts (starting biases: "...1|ind") 
and slopes (learning rates: "(Colour.difference-1|...") of different inds, 
using the Generlized Linear Mixed Effects Regression (glmer) command

**MAKING SEX A RANDOM EFFECT WAS A MISTAKE, NOT ENOUGH LEVELS, AND COMPLETELY
OBSERVED.**

**N.B. There are not enough observations to estimate random effects of chick**
**and batch across Colour.difference:target:background**

As it happens, batches are shared across backgrounds wheras chicks are unique to each condition. It might make more sense to look at random effects of chick on 
CD only.

```{r}
nonpsych1 <- glmer(cbind(corr,incorr)~Colour.difference*background*target*sex + (1+Colour.difference|chick)+ (1+Colour.difference*background|batch), data = data, family = binomial(link = 'logit'))
```

Needs a little help converging, increase tolerance.

```{r}
print(.Machine$double.eps * 10^8)
nonpsych2 <- glmer(cbind(corr,incorr)~Colour.difference*background*target*sex + (1+Colour.difference|chick)+ (1+Colour.difference*background|batch), data = data, family = binomial(link = 'logit'), control = glmerControl(tol = .Machine$double.eps * 10^8))
```


Fit a logistic regression using no information about experience, but controlling for the same random effects, as a test for an effect of experience on response (learning)

```{r}
nonpsych0 <- glmer(cbind(corr,incorr)~1 + (1|chick)+ (1|batch), data = data, family = binomial(link = 'logit'))
```


### Compare the variance in the data explained by experience

```{r}
anova(nonpsych0, nonpsych1, nonpsych2, test = 'Chisq') 
```

The model taking experience into account deviates less from the data recorded (there is an effect of experience).

```{r}
anova(nonpsych0, nonpsych2, test = 'Chisq')
```

For more complex models, Akaike Information Criteria (AIC) may be compared.

```{r}
AIC(nonpsych0, nonpsych1, nonpsych2) # 
```

The model with fixed effects has lower AIC, indicating a better fit 

```{r message=FALSE, warning=FALSE}
resplot(nonpsych2)#looks good
shapiro.test(residuals(nonpsych2)) # even passes a Shapiro-Wilk test
simulateResiduals(nonpsych2,  n=10^3, plot = T, refit = T)
mtext(formula(nonpsych2), side = 3, outer = F, line = 1)

```

Get the model summary for nonpsych2.

```{r}
summary(nonpsych2)
```

Look for candidate variables to remove

```{r}
anova(nonpsych2)[order(anova(nonpsych2)$`F value`),]
```


```{r}
nonpsych.a<- update(nonpsych2,.~.-Colour.difference:background:target:sex)#4way
formula(nonpsych.a)
nonpsych.b<- update(nonpsych.a,.~.-Colour.difference:target:sex)#3way
formula(nonpsych.b)
nonpsych.c<- update(nonpsych.b,.~.-Colour.difference:background:sex )#3way
formula(nonpsych.c)
nonpsych.d<- update(nonpsych.c,.~.-Colour.difference:background:target )#3way
formula(nonpsych.d)
nonpsych.e<- update(nonpsych.d,.~.-background:target:sex  )#3way
formula(nonpsych.e)
nonpsych.f<- update(nonpsych.e,.~.-Colour.difference:sex  )#2way
formula(nonpsych.f)
nonpsych.g<- update(nonpsych.f,.~.-background:sex )#2way
formula(nonpsych.g)
```


If we remove Colour.difference:background, we also have to remove (1+Colour.difference*background|batch) and replace it with + (1+Colour.difference+background|batch)

Otherwise all variance attributed to the interaction can be still be attributed
to its random effect. I find that implausible.

```{r}
nonpsych.h<- update(nonpsych.g,.~.-Colour.difference:background -
				(1+Colour.difference*background|batch) + 
			+ (1+Colour.difference+background|batch) )#2way
formula(nonpsych.h)
nonpsych.i<- update(nonpsych.h,.~.-background:target)#2way
formula(nonpsych.i)
nonpsych.j<- update(nonpsych.i, ~.-Colour.difference:target  )#2way
formula(nonpsych.j)
nonpsych.k<- update(nonpsych.j,.~.-target:sex)#2way
formula(nonpsych.k)
```

If we remove background, we also have to remove (1+Colour.difference+background|batch) and replace it with + (1+Colour.difference|batch)

```{r}
nonpsych.l<- update(nonpsych.k,.~.-background -
				(1+Colour.difference+background|batch) +
				(1+Colour.difference|batch) )#1way
formula(nonpsych.l)
nonpsych.m<- update(nonpsych.l,.~.-sex)#1way
formula(nonpsych.m)
nonpsych.n<- update(nonpsych.m,.~.-target)#1way
formula(nonpsych.n)
```

If we remove Colour.difference, we also have to remove
(1+Colour.difference|batch) and (1+Colour.difference|chick) and replace them 
with (1|chick) + (1|batch)

```{r}
nonpsych.o<- update(nonpsych.n,.~.-Colour.difference - 
				(1+Colour.difference|chick) +
				(1+Colour.difference|batch) -
				(1|chick) + (1|batch) )
```


```{r}
formula(nonpsych.o)#same as nonpsych0, no fixed effects left to remove
anova(nonpsych2, nonpsych.a, nonpsych.b, nonpsych.c, nonpsych.d, nonpsych.e, nonpsych.f, nonpsych.g, nonpsych.h, nonpsych.i, nonpsych.j, nonpsych.k, nonpsych.l, nonpsych.m, nonpsych.n, nonpsych.o)
anova(nonpsych2, nonpsych.a, nonpsych.b, nonpsych.c, nonpsych.d, nonpsych.e, nonpsych.f, nonpsych.g, nonpsych.h, nonpsych.i, nonpsych.j, nonpsych.k, nonpsych.l, nonpsych.m, nonpsych.n, nonpsych.o)[order(row.names(anova(nonpsych2, nonpsych.a, nonpsych.b, nonpsych.c, nonpsych.d, nonpsych.e, nonpsych.f, nonpsych.g, nonpsych.h, nonpsych.i, nonpsych.j, nonpsych.k, nonpsych.l, nonpsych.m, nonpsych.n, nonpsych.o))),]
```

We use the anova functon to compare AIC scores of model deviance.				

```{r}
anova(nonpsych2, nonpsych.a, nonpsych.b, nonpsych.c, nonpsych.d, nonpsych.e, nonpsych.f, nonpsych.g, nonpsych.h, nonpsych.i, nonpsych.j, nonpsych.k, nonpsych.l, nonpsych.m, nonpsych.n, nonpsych.o)[rev(order(AIC(nonpsych2, nonpsych.a, nonpsych.b, nonpsych.c, nonpsych.d, nonpsych.e, nonpsych.f, nonpsych.g, nonpsych.h, nonpsych.i, nonpsych.j, nonpsych.k, nonpsych.l, nonpsych.m, nonpsych.n, nonpsych.o)$AIC)),]
```


```{r}
anova(nonpsych2, nonpsych.a)
```


## Setting up the fitted function

```{r}
xseq <- unique(data$Colour.difference) # imaginary stimulus levels to fit to. Change the high and low values, the two values after seq(,  to fit to your datas stimulus levels
 newdata <- expand.grid(Colour.difference =xseq, background=unique(data$background),target=unique(data$target), sex = unique(data$sex), chick = unique(data$chick), batch = unique(data$batch))
nonpsych1.pred <- predict(nonpsych2, newdata = data.frame(Colour.difference = data$Colour.difference, background = data$background, target = data$target, sex = data$sex), type="response", re.form = NA)#,se.fit=TRUE) ##Setting up the real data from the function
nonpsych2.pred <- predict(nonpsych2, newdata = newdata, type="response")#,se.fit=TRUE) ## Setting up the imaginary data from the function
plot(data$Colour.difference, nonpsych1.pred)
```

## Setting up the plot

```{r message=FALSE, warning=FALSE}
bktg <- data.frame(bk = levels(data$background)[c(1,2,2,1)],
					tg = rev(levels(newdata$target))[c(1,2,1,2)])
for(i in 1:dim(bktg)[1]){
	bk <- bktg$bk[i]		
	tg <- bktg$tg[i]			
plot(NULL, xlab="Colour difference", ylab="Proportion correct", xlim=c(0, 6), ylim=c(0.4, 1), main = paste('background =',bk, ', target =',tg))
				if(bk == 'green' & tg == 'same'){
			legend('bottomright', legend = c('Male', 'Female', paste('Batch',c('A','B','C','D'))), 
		col = c(2*(2:1), rep(1, 4)), lty = c(1,1,1:4), pch = c(24,22,rep(NA,4)), cex = 0.7)
			}
			for(ck in levels(newdata$chick)){
				if(sum(data$background == bk & data$chick == ck & data$target == tg)){
				sx <- unique(subset(data, chick == ck)$sex)
				bc <- unique(subset(data, chick == ck)$batch)
				xx <- subset(newdata, background == bk & chick == ck & target == tg & sex == sx & batch == bc)
				yy <- nonpsych2.pred[newdata$background == bk & newdata$chick == ck & newdata$target == tg & newdata$sex == sx & newdata$batch == bc]
				ORDER <- order(xx$Colour.difference)#Order!
			lines(xx$Colour.difference[ORDER], yy[ORDER], col = 2*which(unique(subset(data, chick == ck)$sex) == levels(newdata$sex)), lty = which(unique(subset(data, chick == ck)$batch) == levels(newdata$batch)), lwd = 0.5 )
			}
			}
points(data$Colour.difference[data$background == bk & data$target == tg], data$pcorr[data$background == bk & data$target == tg], pch = c(22,24)[as.numeric(data$sex[data$background == bk & data$target == tg])], bg = 'white', col = rgb(0,0,0,0.3), lwd = 2)
}
```

The following chunk defines the colout series.

```{r}
cls<-c("purple4","slateblue3","slateblue2","red3","green3","slateblue1","pink3","orange3","navajowhite4","gray50","gray70","gray30","darkblue","navajowhite2","orange4","steelblue","gray10",	"purple3","magenta4","slateblue4","green2","blue2","darkred","darkgreen","orange2","seagreen","salmon4","navajowhite1","navajowhite3","yellow3", "blue3","magenta3")
```

#shorten as.factor for use in level sortin
#N.B. unique(x) may have been more efficient than levels(as.factor(x))
```{r}
AF <- function(x){as.factor(x)}
```

#panels to plot in vertical and horizontal direction

```{r message=FALSE, warning=FALSE}
hw <- c(2,2)
par(mfrow = c(hw), mai = .75*c(.8,1,.5,0))
bktg <- data.frame(bk = levels(data$background)[c(1,2,2,1)],
					tg = rev(levels(newdata$target))[c(1,2,1,2)])
for(i in 1:dim(bktg)[1]){
	bk <- bktg$bk[i]		
	tg <- bktg$tg[i]		

plot(NULL, xlab="Colour difference", ylab="Proportion correct", xlim=c(0, 6), ylim=c(0.4, 1), main = paste('background =',bk, ', target =',tg))
legend(4, .7, levels(AF(data$chick[data$target == tg & data$background == bk])), col = cls[which(	levels(AF(data$chick)) %in% levels(AF(data$chick[data$target == tg & data$background == bk])))], pch = c(22,24)[as.numeric(data$sex[data$Colour.difference == max(data$Colour.difference[data$chick %in% levels(AF(data$chick[data$target == tg & data$background == bk]))]) & data$chick %in% levels(AF(data$chick[data$target == tg & data$background == bk]))] )],
 cex = 1, bty = 'n', lwd = 1, lty = as.numeric( subset(data, chick %in% levels(AF(data$chick[data$target == tg & data$background == bk])) & data$Colour.difference == max(data$Colour.difference[data$chick %in% levels(AF(data$chick[data$target == tg & data$background == bk]))]) )$batch ) )
				if(bk == 'green' & tg == 'diff'){
			legend('bottomright', legend = c('Male', 'Female', paste('Batch',c('A','B','C','D'))), 
		col = c(2*(2:1), rep(1, 4)), lty = c(1,1,1:4), pch = c(24,22,rep(NA,4)), cex = 0.7)
			}
			for(ck in levels(newdata$chick)){
				if(sum(data$background == bk & data$chick == ck & data$target == tg)){
				sx <- unique(subset(data, chick == ck)$sex)
				bc <- unique(subset(data, chick == ck)$batch)
				xx <- subset(newdata, background == bk & chick == ck & target == tg & sex == sx & batch == bc)
				yy <- nonpsych2.pred[newdata$background == bk & newdata$chick == ck & newdata$target == tg & newdata$sex == sx & newdata$batch == bc]
			ORDER <- order(xx$Colour.difference)#Order!
			lines(xx$Colour.difference[ORDER], yy[ORDER], col = cls[which(levels(AF(data$chick)) == ck)], lty = which(unique(subset(data, chick == ck)$batch) == levels(newdata$batch)), lwd = 0.5 ) 
			points(data$Colour.difference[data$background == bk & data$chick == ck & data$target == tg & data$sex == sx & data$batch == bc], data$pcorr[data$background == bk & data$chick == ck & data$target == tg & data$sex == sx & data$batch == bc], pch = c(22,24)[as.numeric(data$sex[data$background == bk & data$target == tg & data$chick == ck])], bg = 'white', col = cls[which(levels(AF(data$chick)) == ck)], lwd = 2)
			}
			}
}
ndata <- expand.grid(Colour.difference =xseq, background=unique(data$background), target=unique(data$target))

prd <- predict(nonpsych2, newdata = newdata, type="response", re.form = NA)
pfun <- function(x){predict(x, newdata = newdata, type = 'response')}
```

Bootstrapped model of 

```{r}
boot <- bootMer(nonpsych2, pfun, nsim = 10^2, re.form = NA, parallel = c("multicore"), ncpus = parallel::detectCores())
stqlog	 <- function(x){ sd(qlogis(x), na.rm = T)}
std.err <- apply(boot$t, 2, stqlog)#standard error for each
CI.lo <- plogis(qlogis(prd) - std.err*1.96)#lower confidence bound (parametric)
CI.hi <- plogis(qlogis(prd) + std.err*1.96)#upper confidence bound (parametric)
bootsdata <- cbind(newdata, CI.lo, CI.hi)
CI.lo. <- with(bootsdata, aggregate(CI.lo, list(Colour.difference = Colour.difference, background = background, target = target), mean))
CI.hi. <- with(bootsdata, aggregate(CI.hi, list(Colour.difference = Colour.difference, background = background, target = target), mean))
```



```{r}
ciii <- confint(boot, parallel = c("multicore"),ncpus = parallel::detectCores())
paramdata <- cbind(newdata, ciii)
#mean should be in logit space
lgtmean <- function(x){plogis(mean(qlogis(x)))}
CI.02.5 <- with(paramdata, aggregate(`2.5 %`, list(Colour.difference = Colour.difference, background = background, target = target), lgtmean))#mean))
CI.97.5 <- with(paramdata, aggregate(`97.5 %`, list(Colour.difference = Colour.difference, background = background, target = target), lgtmean))#mean))
```


### Find sensible averages for each condition

```{r}
estdata <- cbind(newdata, prd)[order(newdata$Colour.difference),]
estcurve <- with(estdata, aggregate(prd, list(Colour.difference = Colour.difference, background = background, target = target), lgtmean))

threshquant <- list(same = (0:20/100), diff = (0:40/100))
```


```{r message=FALSE, warning=FALSE}
hw <- c(2,2)
par(mfrow = c(hw), mai = .75*c(.8,1,.5,0))
bktg <- data.frame(bk = levels(data$background)[c(1,2,2,1)],
					tg = rev(levels(newdata$target))[c(1,2,1,2)])
for(i in 1:dim(bktg)[1]){
	bk <- bktg$bk[i]		
	tg <- bktg$tg[i]		
	plot(NULL, xlab="Colour difference", ylab="Proportion correct", xlim=c(0, 6), ylim=c(0.4, 1), main = paste('background =',bk, ', target =', tg))

				xx <- subset(estcurve, background == bk & target == tg)$Colour.difference
				yy <- subset(estcurve, background == bk & target == tg)$x
				threshness <-abs(yy - 0.65)
				threshx <- mean(xx[threshness %in% quantile(threshness, unlist(threshquant[2 - i %% 2])) ])
				print(threshx)
						polygon(c(subset(CI.02.5, background == bk & ndata$target == tg)$Colour.difference, rev(subset(CI.97.5, background == bk & ndata$target == tg)$Colour.difference)), c(subset(CI.02.5, background == bk & ndata$target == tg)$x,rev(subset(CI.97.5, background == bk & ndata$target == tg)$x)) , col = 'gray', border = rgb(0,0,0,0))
			# lines(xx[ORDER], yy[ORDER], col = 'black', lty = 1, lwd = 5)
				lines(xx, yy, col = 'black', lty = 1, lwd = 1)

points(data$Colour.difference[data$background == bk & data$target == tg], data$pcorr[data$background == bk & data$target == tg], pch = c(22,24)[as.numeric(data$sex[data$background == bk & data$target == tg])], bg = 'white', col = rgb(0,0,0,0.3), lwd = 2)
lines(rep(threshx, 2), c(0.36, 0.65), lty = 2)
lines(c(-0.25,threshx), rep(0.65,2), lty = 2)
}
legend('bottomright', legend = c('Male', 'Female'), 
		col = c(1,1), pch = c(24,22), lwd = c(2,2))

std.err <- apply(boot$t, 2, stqlog)#standard error for each
CI.lo.se <- plogis(qlogis(prd) - std.err)#lower se bound (parametric)
CI.hi.se <- plogis(qlogis(prd) + std.err)#upper se bound (parametric)
bootsdata.se <- cbind(newdata, CI.lo.se, CI.hi.se)
CI.lo.se. <- with(bootsdata.se, aggregate(CI.lo.se, list(Colour.difference = Colour.difference, background = background, target = target), lgtmean))
CI.hi.se. <- with(bootsdata.se, aggregate(CI.hi.se, list(Colour.difference = Colour.difference, background = background, target = target), lgtmean))
```

Make a function to evaluate the threshold.

```{r}
thresholder <- function(xx,yy,lev){
				diff. <- sort(yy-lev)
				close. <- min(abs(diff.))
				if(sign(diff.[abs(diff.) == close.]) == 0){
					return(	xx[which(abs(diff.) == close.) + c(0)]	)
				}else{
					if(sign(diff.[abs(diff.) == close.]) == 1){
						if(which(abs(diff.) == close.) == 1){
						return(	xx[1])
						}else{
					ab. <-  xx[which(abs(diff.) == close.) + c(-1,0)]
						}
					}else{
					ab. <-  xx[which(abs(diff.) == close.) + c(0,1)]
					}
					ty. <- yy[xx %in% ab.]
				xxt. <- seq(min(ab.), max(ab.), length.out = 10^3)
				yyt. <- (xxt.-min(ab.))*diff(ty.)/diff(ab.) + min(ty.)
				return(	mean(xxt.[round(yyt.,2) == lev])	)
				}
}
```


```{r}
par(mfrow = c(hw), mai = .75*c(.8,1,.5,0))
	
for(i in 1:dim(bktg)[1]){
	bk <- bktg$bk[i]		
	tg <- bktg$tg[i]		
	plot(NULL, xlab="Colour difference", ylab="Proportion correct",
	     xlim=c(0, 6),  ylim=c(0.4, 1),
	     main = paste('background =',bk, ', target =', tg))
	abline(h = 0.65, lty = 2, lwd = 0.5)
	x1 <- subset(estcurve, background == bk & target == tg)$Colour.difference
	y1 <- subset(estcurve, background == bk & target == tg)$x
	xx <- sort(unique(subset(CI.lo.se., background == bk & target==tg)$Colour.difference ))
	yy.lo <- sort(unique(	subset(CI.lo.se., background == bk & target == tg)$x	))
	yy.hi <- sort(unique(	subset(CI.hi.se., background == bk & target == tg)$x	))
	lines(xx, yy.lo)
	lines(xx, yy.hi)
	lines(x1, y1, col = 'darkgreen')
	assign(paste0('t.', tg, bk), thresholder(x1,y1,0.65))
	lines(rep(get(paste0('t.', tg, bk)),2), c(0.38, 0.65), lty = 2, col = 'green')
	assign(paste0('t.se.lo.', tg, bk), thresholder(xx,yy.hi,0.65))
	lines(rep(get(paste0('t.se.lo.', tg, bk)),2), c(0.38, 0.65), lty = 2,col ='red')
				assign(paste0('t.se.hi.', tg, bk), thresholder(xx,yy.lo,0.65))
	lines(rep(get(paste0('t.se.hi.', tg, bk)),2), c(0.38, 0.65), lty = 2,col ='blue')
	}
```

## The "binomial" 65% threshold
JND for chickens discriminating orange colours on an orange background

```{r}
diff(round(	c(
			t.se.lo.sameorange, 
			t.se.hi.sameorange	),	2)
			)
```

JND for chickens discriminating orange colours on a green background

```{r}
diff(round(	c(
			t.se.lo.diffgreen, 
			t.se.hi.diffgreen	),	2)
      )
```

				
JND for chickens discriminating green colours on an orange background.

```{r}
diff(round(	c(
			t.se.lo.difforange, 
			t.se.hi.difforange	),	2)
)

```

JND for chickens discriminating green colours on an green background.

```{r}
diff(round(	c(
			t.se.lo.samegreen, 
			t.se.hi.samegreen	),	2)
)
```


